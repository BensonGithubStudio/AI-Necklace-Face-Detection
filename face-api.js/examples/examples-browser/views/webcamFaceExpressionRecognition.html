<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
  <style>
    #jsonPrompt {
      color: green;
      font-weight: bold;
      font-size: 1.2em;
      text-align: center;
      margin-top: 10px;
      visibility: hidden; /* 初始隱藏 */
    }

    /* 新增的顯示結果區塊 */
    #expressionResults {
      margin-top: 20px;
      padding: 15px;
      background-color: #f4f7fc;
      border-radius: 8px;
      text-align: center;
      font-size: 1.1em;
    }
  </style>
</head>
<body>
  <div id="navbar"></div>
  <div class="center-content page-container">
    <h4><strong>表情辨識系統</strong></h4>
    <div style="position: relative" class="margin">
      <video onloadedmetadata="onPlay()" id="inputVideo" autoplay muted playsinline></video>
      <canvas id="overlay"></canvas>
    </div>
    <!-- 提示字區塊 -->
    <div id="jsonPrompt">JSON 已加入列表</div>

    <!-- 顯示表情辨識結果的區域 -->
    <div id="expressionResults">正在分析表情...</div>

    <!-- 新增下載按鈕 -->
    <div style="margin-top: 20px;">
      <button onclick="downloadAllData('json')" class="waves-effect waves-light btn">下載 JSON</button>
      <button onclick="downloadAllData('csv')" class="waves-effect waves-light btn">下載 CSV</button>
    </div>
  </div>

  <script>
    let expressionDataList = []; // 累積所有辨識結果的陣列
    let faceInFrameTime = null; // 記錄人臉出現在畫面中的時間
    let isSaved = false; // 防止重複儲存
    let isFaceCurrentlyDetected = false;

    async function onPlay() {
      const videoEl = document.getElementById('inputVideo');

      if (videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded()) {
        return setTimeout(() => onPlay());
      }

      const options = getFaceDetectorOptions();
      const result = await faceapi.detectSingleFace(videoEl, options).withFaceExpressions();

      if (result) {
        if (!isFaceCurrentlyDetected) {
          // 人臉首次出現，記錄時間
          faceInFrameTime = Date.now();
          isFaceCurrentlyDetected = true;
          isSaved = false; // 重置儲存狀態
        } else if (Date.now() - faceInFrameTime >= 3000 && !isSaved) {
          // 人臉已持續3秒且尚未儲存
          saveExpressionData(result);
          isSaved = true; // 設置為已儲存
          showJsonPrompt(); // 顯示提示字

          // 跳轉到 ObjectDetect.html 頁面
          window.location.href = "ObjectDetect.html";
        }

        // 更新顯示表情辨識結果
        updateExpressionResults(result.expressions);

        // 繪製邊界框和表情
        const canvas = document.getElementById('overlay');
        const dims = faceapi.matchDimensions(canvas, videoEl, true);
        const resizedResult = faceapi.resizeResults(result, dims);

        faceapi.draw.drawDetections(canvas, resizedResult);
        faceapi.draw.drawFaceExpressions(canvas, resizedResult, 0.05);
      } else {
        // 人臉離開畫面，重置狀態
        isFaceCurrentlyDetected = false;
        faceInFrameTime = null;
        isSaved = false;
      }

      setTimeout(() => onPlay());
    }

    // 儲存表情資料到陣列
    function saveExpressionData(result) {
      const timestamp = new Date().toISOString();
      const expressionData = {
        timestamp,
        neutral: result.expressions.neutral.toFixed(2),
        happy: result.expressions.happy.toFixed(2),
        sad: result.expressions.sad.toFixed(2),
        angry: result.expressions.angry.toFixed(2),
        disgusted: result.expressions.disgusted.toFixed(2),
        surprised: result.expressions.surprised.toFixed(2),
        fearful: result.expressions.fearful.toFixed(2)
      };
      expressionDataList.push(expressionData); // 累積資料
      console.log("儲存表情資料:", expressionData);
    }

    // 顯示 JSON 提示字並自動隱藏
    function showJsonPrompt() {
      const prompt = document.getElementById("jsonPrompt");
      prompt.style.visibility = "visible"; // 顯示提示字
      setTimeout(() => {
        prompt.style.visibility = "hidden"; // 2 秒後隱藏
      }, 2000);
    }

    // 更新表情結果顯示
    function updateExpressionResults(expressions) {
      const expressionResults = document.getElementById("expressionResults");
      expressionResults.innerHTML = `
        <strong>表情分析結果:</strong><br>
        Neutral: ${expressions.neutral.toFixed(2)}<br>
        Happy: ${expressions.happy.toFixed(2)}<br>
        Sad: ${expressions.sad.toFixed(2)}<br>
        Angry: ${expressions.angry.toFixed(2)}<br>
        Disgusted: ${expressions.disgusted.toFixed(2)}<br>
        Surprised: ${expressions.surprised.toFixed(2)}<br>
        Fearful: ${expressions.fearful.toFixed(2)}<br>
      `;
    }

    // 下載 JSON 或 CSV 檔案
    function downloadAllData(format) {
      if (expressionDataList.length === 0) {
        alert("尚未偵測到任何表情資料。");
        return;
      }

      if (format === 'json') {
        const jsonContent = JSON.stringify(expressionDataList, null, 2);
        downloadFile(jsonContent, 'application/json', 'expressions.json');
      } else if (format === 'csv') {
        const headers = ["Timestamp", "Neutral", "Happy", "Sad", "Angry", "Disgusted", "Surprised", "Fearful"];
        const rows = expressionDataList.map(data => [
          data.timestamp,
          data.neutral,
          data.happy,
          data.sad,
          data.angry,
          data.disgusted,
          data.surprised,
          data.fearful
        ]);
        const csvContent = [headers.join(",")].concat(rows.map(row => row.join(","))).join("\n");
        downloadFile(csvContent, 'text/csv;charset=utf-8;', 'expressions.csv');
      }
    }

    // 觸發下載檔案的功能
    function downloadFile(content, mimeType, filename) {
      const blob = new Blob([content], { type: mimeType });
      const link = document.createElement("a");
      link.href = URL.createObjectURL(blob);
      link.download = filename;
      link.click();
    }

    async function run() {
      await changeFaceDetector(TINY_FACE_DETECTOR);
      await faceapi.loadFaceExpressionModel('/');
      changeInputSize(224);

      const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
      const videoEl = document.getElementById('inputVideo');
      videoEl.srcObject = stream;
    }

    $(document).ready(function () {
      renderNavBar('#navbar', 'webcam_face_expression_recognition');
      run();
    });
  </script>
</body>
</html>
